{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bedc536f-4c92-4634-a0ba-472d6990dd74",
   "metadata": {},
   "source": [
    "## 1. Equality-constrained Least  Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a414489d-f49b-4ccf-8716-8144ad776737",
   "metadata": {},
   "source": [
    "$\\begin{align*}\n",
    "    \\min f(x): \\quad & \\left|Ax - b \\right|^2 : \\\\\n",
    "    & Cx - e = 0 \\\\\n",
    "\\end{align*}$\n",
    "\n",
    "$\\rightarrow$\n",
    "\n",
    "**KKT Conditions**\n",
    "\n",
    "$\\begin{align*}\n",
    "    \\nabla_x L(x^*, \\nu^*) = 0 \\\\\n",
    "    Cx^* - e = 0 \\\\\n",
    "\\end{align*}$\n",
    "\n",
    "Recall that $L(x, \\nu) := \\left|Ax - b \\right|^2 + \\nu^T(Cx-e)$\n",
    "\n",
    "Thus, $\\nabla_x L(x^*, \\nu^*) = 2A^TAx^* - 2A^Tb + C^T\\nu^* = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244843de-be25-4a98-b662-ac4b2bf0b5e9",
   "metadata": {},
   "source": [
    "## 2. Equality-constrained Convex Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a653ae-75ce-4056-99b4-f14c5529db0c",
   "metadata": {},
   "source": [
    "$\\begin{align*}\n",
    "    \\min f(x): \\quad & Ax = b \\\\\n",
    "\\end{align*}$\n",
    "\n",
    "$\\rightarrow$\n",
    "\n",
    "**KKT Conditions**\n",
    "\n",
    "$\\begin{align*}\n",
    "    \\nabla_x L(x^*, \\nu^*) = 0 \\\\\n",
    "    \\nabla_{\\nu} L(x^*, \\nu^*) = 0 \\\\\n",
    "\\end{align*}$\n",
    "\n",
    "$L(x, \\nu) := f(x) + \\nu^T(Ax - b)$\n",
    "\n",
    "$\\nabla_{\\nu} = Ax^* - b$\n",
    "\n",
    "By the Strong Duality Theorem, $p^* = d^*$ for convex optimization under a mild condition.\n",
    "\n",
    "$d^* = \\max_{\\nu} g(\\nu) = \\max_{\\nu} \\min_{x \\in X} L(x, \\nu)$\n",
    "\n",
    "1. $L(x, \\nu)$ is convex in x\n",
    "2. $\\min_{x \\in X} L(x, \\nu)$ is unconstrained w.r.t x $x \\in X$\n",
    "3. Recall that for convex function $f$, $x^* = arg \\min_{x \\in X} f(x)$ iff $\\nabla f(x^*) = 0$\n",
    "\n",
    "Thus, the optimality condition for the inner minimization problem $\\min_{x \\in X} L(x, \\nu)$ is:\n",
    "\n",
    "$\\nabla_x L(x^*(\\nu), \\nu^*) = 0$\n",
    "\n",
    "where $x^*(\\nu) = arg \\min_{x \\in X} L(x, \\nu)$\n",
    "\n",
    "1. $\\min_{x \\in X} L(x, \\nu)$ is concave in $\\nu$\n",
    "2. $\\max_{\\nu} \\min_{x \\in X} L(x, \\nu$ is unconstrained w.r.t $\\nu\\$\n",
    "\n",
    "Similarly, the optimality condition for the outer maximization problem $\\max_{\\nu} \\min_{x \\in X} L(x, \\nu)$ is:\n",
    "\n",
    "$\\nabla_{\\nu} L(x^*(\\nu^*), \\nu^*) = 0$\n",
    "\n",
    "where $L(x^*(\\nu), \\nu) = \\min_{x \\in X} L(x, \\nu)$\n",
    "\n",
    "Thus, the optimality condition reduces to the KKT Condition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded007ae-941f-444a-8371-4b001c0234d7",
   "metadata": {},
   "source": [
    "## 3. General Convex Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af3b5af-a820-47bd-a21b-0f5995928819",
   "metadata": {},
   "source": [
    "If we consider inequality constraints,\n",
    "\n",
    "**Interior Point Method (IPM)** can approximate KKT conditions.\n",
    "\n",
    "Idea of IPM:\n",
    "1. Approximate the primal problem into an equality-constrained problem\n",
    "2. Apply equality-constraint-tailored algorithms to the approximated optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71c894c-cc48-4034-8bf1-a214e23da797",
   "metadata": {},
   "source": [
    "$\\begin{align*}\n",
    "    \\min f(x): \\quad & f_i(x) \\le 0 \\quad & \\forall{i} \\in [m], \\\\\n",
    "    & Ax = b \\\\\n",
    "\\end{align*}$\n",
    "\n",
    "* If $f_i(x) \\le 0$, then make no change to $f(x)$\n",
    "* If $f_i(x) > 0$, then make the optimization problem infeasible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2393204-2b78-48b8-88b6-1be616188342",
   "metadata": {},
   "source": [
    "<img src = './img/week13_1.png' style = \"width = 700px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5e1b70-3a48-408f-b27a-4ed6a54a0c7c",
   "metadata": {},
   "source": [
    "Reformulated Problem : $\\min f(x) + \\sum_{i=1}^m I\\_(f_i(x)) : Ax = b$\n",
    "\n",
    "But since $I\\_(f_i(x))$ is not differentiable, no algorithms can solve KKT conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686dcd8e-2be3-4ef5-bce6-4d5afa9b0319",
   "metadata": {},
   "source": [
    "**Solution** : Surrogate Barrier Function\n",
    "\n",
    "Surrogate $\\rightarrow$\n",
    "\n",
    "Logarithmic Barrier : $LB(z) := -\\mu log(-z)$ for $\\mu > 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99353a6-3566-404b-83ef-bff63bfe8cb2",
   "metadata": {},
   "source": [
    "### Approximated convex Optimization\n",
    "\n",
    "$\\min f(x) + -\\mu\\sum_{i=1}^m log(-f_i(x)) : Ax = b$\n",
    "\n",
    "The cost function is convex, since if $f$ and $g$ are convex functions and $g$ is non-decreasing, then $g(f(x))$ is convex in $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb60e3f-e99a-4767-a436-8494d8368c96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
